def query_dataframe(input: QueryDataFrameInput) -> str:
    # Extract parameters
    liquidity_variable_input = input.liquidity_variable.lower().strip()
    time_to_maturity = input.time_to_maturity
    region = input.region
    fi_nonfi = input.fi_nonfi
    ig_nonig = input.ig_nonig

    # Map liquidity_variable
    liquidity_variable_mapping = {
        'japanese government bond': 'jp government bonds',
        'uk corporate bond': 'uk corporate bonds',
        'australian government bond': 'aus government bonds',
        # Add more mappings as needed
    }

    liquidity_variable = liquidity_variable_mapping.get(liquidity_variable_input, liquidity_variable_input)

    # Normalize DataFrame columns for consistent comparison
    df_liquidity['Liquidity Variable'] = df_liquidity['Liquidity Variable'].str.lower().str.strip()
    df_liquidity['Region'] = df_liquidity['Region'].str.lower().str.strip()
    df_liquidity['FI_NonFI'] = df_liquidity['FI_NonFI'].str.lower().str.strip()
    df_liquidity['IG_NonIG'] = df_liquidity['IG_NonIG'].str.lower().str.strip()
    df_liquidity['Time to Maturity'] = df_liquidity['Time to Maturity'].str.lower().str.strip()

    # Apply filters
    query_df = df_liquidity.copy()

    # Liquidity Variable filter
    query_df = query_df[query_df['Liquidity Variable'] == liquidity_variable]
    if query_df.empty:
        return f"No data found for Liquidity Variable: {liquidity_variable_input}"

    # Time to Maturity mapping and filter
    if time_to_maturity:
        time_to_maturity = time_to_maturity.lower().strip()

        # Map specific years to '< 5 years' or '> 5 years'
        ttm_mapping = {
            '1 year': '< 5 years',
            '2 years': '< 5 years',
            '3 years': '< 5 years',
            '4 years': '< 5 years',
            '5 years': '< 5 years',
            '6 years': '> 5 years',
            '7 years': '> 5 years',
            '8 years': '> 5 years',
            '9 years': '> 5 years',
            '10 years': '> 5 years',
        }
        mapped_ttm = ttm_mapping.get(time_to_maturity, time_to_maturity)
        query_df = query_df[query_df['Time to Maturity'] == mapped_ttm]
        if query_df.empty:
            return f"No data found for Time to Maturity: {time_to_maturity}"

    # Region filter
    if region:
        region = region.lower().strip()
        query_df = query_df[query_df['Region'] == region]
        if query_df.empty:
            return f"No data found for Region: {region}"

    # FI_NonFI filter
    if fi_nonfi:
        fi_nonfi = fi_nonfi.lower().strip()
        query_df = query_df[query_df['FI_NonFI'] == fi_nonfi]
        if query_df.empty:
            return f"No data found for FI_NonFI: {fi_nonfi}"

    # IG_NonIG filter
    if ig_nonig:
        ig_nonig = ig_nonig.lower().strip()
        query_df = query_df[query_df['IG_NonIG'] == ig_nonig]
        if query_df.empty:
            return f"No data found for IG_NonIG: {ig_nonig}"

    if query_df.empty:
        return "No data found for the given parameters."

    # Limit DataFrame to first 10 columns
    query_df = query_df.iloc[:, :10]

    # Convert DataFrame to a string representation
    result_table = query_df.to_markdown(index=False)

    # Return the result as a string
    return f"Here are the results based on your query:\n\n{result_table}"


RETRIEVER -------
Option 1 (multi-retriever):
from langchain.chains import RetrievalQA
from langchain.retrievers.multi_query import MultiQueryRetriever

# Initialize the multi-query retriever
multi_query_retriever = MultiQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(search_kwargs={"k": 10}),
    llm=llm
)

# Create the RetrievalQA chain
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=multi_query_retriever
)

Option 2 (bm25):
from langchain.retrievers import BM25Retriever
from langchain.docstore.document import Document
bm25_retriever = BM25Retriever.from_documents(documents)
bm25_retriever.k = 10
# Initialize the vectorstore retriever
vectorstore_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

from typing import List
from langchain.schema import BaseRetriever

class EnsembleRetriever(BaseRetriever):
    def __init__(self, retrievers: List[BaseRetriever], weights: List[float]):
        self.retrievers = retrievers
        self.weights = weights

    def get_relevant_documents(self, query: str) -> List[Document]:
        # Get results from each retriever
        results = []
        for retriever, weight in zip(self.retrievers, self.weights):
            docs = retriever.get_relevant_documents(query)
            # Assign a score based on the weight
            for doc in docs:
                doc.metadata['score'] = doc.metadata.get('score', 0) + weight
            results.extend(docs)
        
        # Remove duplicates by doc ID or content
        unique_results = {}
        for doc in results:
            key = doc.metadata.get('source', doc.page_content)
            if key in unique_results:
                # If already exists, sum the scores
                unique_results[key].metadata['score'] += doc.metadata['score']
            else:
                unique_results[key] = doc

        # Sort documents by the combined score
        sorted_docs = sorted(unique_results.values(), key=lambda d: d.metadata['score'], reverse=True)

        # Return top k documents
        top_k = 5  # Adjust as needed
        return sorted_docs[:top_k]

    async def aget_relevant_documents(self, query: str) -> List[Document]:
        # Optional: Implement asynchronous retrieval if needed
        pass

# Initialize the ensemble retriever
ensemble_retriever = EnsembleRetriever(
    retrievers=[vectorstore_retriever, bm25_retriever],
    weights=[0.7, 0.3]  # Adjust weights as needed
)

# Create the RetrievalQA chain with the ensemble retriever
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=ensemble_retriever
)

def retrieve_documents(query: str) -> str:
    # Use the qa_chain to retrieve and answer the query
    result = qa_chain.run(query)
    return result

-------------------------------
def visualize_fx_rates(input: VisualizeFXRatesInput) -> str:
    import matplotlib.pyplot as plt
    import matplotlib.dates as mdates
    import numpy as np
    from sklearn.linear_model import LinearRegression
    import matplotlib.cm as cm

    # Extract parameters
    currency_codes = input.currency_codes
    start_period = input.start_period
    end_period = input.end_period
    comparison_type = input.comparison_type.lower()
    chart_type = input.chart_type.lower()
    trend_line = input.trend_line

    # Validate inputs
    if not currency_codes:
        return "Missing required parameter: currency_codes."
    
    # Handle 'YTD' or missing periods
    if start_period is None or end_period is None or 'ytd' in (start_period.lower(), end_period.lower()):
        start_period = 'January'
        end_period = 'August'

    # Convert periods to datetime
    try:
        start_date = pd.to_datetime(f"2023 {start_period}", format='%Y %B')
        end_date = pd.to_datetime(f"2023 {end_period}", format='%Y %B')
    except Exception as e:
        return f"Invalid date format: {e}"

    # Ensure start_date is before end_date
    if start_date > end_date:
        start_date, end_date = end_date, start_date

    # Ensure 'Date' column is correctly parsed
    if not pd.api.types.is_datetime64_any_dtype(df_fx_rates_melted['Date']):
        # Adjust the format string to match your data
        df_fx_rates_melted['Date'] = pd.to_datetime(df_fx_rates_melted['Date'], format='%b-%y', errors='coerce')

    # Check for NaT values and drop them
    df_fx_rates_melted.dropna(subset=['Date'], inplace=True)

    # Ensure 'Currency' codes are uppercase
    df_fx_rates_melted['Currency'] = df_fx_rates_melted['Currency'].str.upper()
    currency_codes = [code.upper() for code in currency_codes]

    # Filter data for the given currency codes
    df_filtered = df_fx_rates_melted[
        df_fx_rates_melted['Currency'].isin(currency_codes)
    ]

    if df_filtered.empty:
        return "No data available for the given currency codes."

    # Filter dates
    df_filtered = df_filtered[
        (df_filtered['Date'] >= start_date) & (df_filtered['Date'] <= end_date)
    ]

    if df_filtered.empty:
        return "No data available for the given date range."

    # Pivot data for easier calculation
    df_pivot = df_filtered.pivot_table(
        index='Date', columns='Currency', values='FX Rate'
    )

    # Ensure data types are numeric
    df_pivot = df_pivot.apply(pd.to_numeric, errors='coerce')

    # Drop columns with all NaN values
    df_pivot.dropna(axis=1, how='all', inplace=True)

    if df_pivot.empty:
        return "No valid FX Rate data available after processing."

    # Plotting
    plt.figure(figsize=(12, 6))

    if chart_type == 'line':
        # Calculate month-over-month percentage differences
        df_pct_change = df_pivot.pct_change().dropna() * 100

        if df_pct_change.empty:
            return "No data available after calculating month-over-month percentage differences."

        title = f"Month-over-Month Percentage Difference in FX Rates from {start_period} to {end_period}"

        # Define a colormap
        colormap = cm.get_cmap('tab10')  # You can choose any colormap you like

        # Plotting
        ax = df_pct_change.plot(marker='o', linewidth=2, colormap=colormap)

        # Remove the line color customization to let Matplotlib assign different colors
        # for line in ax.get_lines():
        #     line.set_color('steelblue')

        # Highlight the line with the highest cumulative change
        cumulative_changes = df_pct_change.sum()
        max_currency = cumulative_changes.idxmax()
        max_line = ax.get_lines()[df_pct_change.columns.get_loc(max_currency)]
        max_line.set_linewidth(3)  # Make the line thicker

        # Annotate the highest line
        max_value = df_pct_change[max_currency].max()
        max_date = df_pct_change[max_currency].idxmax()
        plt.annotate(
            f'Highest: {max_currency}',
            xy=(mdates.date2num(max_date), max_value),
            xytext=(0, 10),
            textcoords='offset points',
            ha='center',
            va='bottom',
            fontsize=10,
            fontweight='bold',
            color='red'
        )

        # Add trend lines if specified
        if trend_line:
            # For each currency, add a trend line
            for i, currency in enumerate(df_pct_change.columns):
                x_vals = mdates.date2num(df_pct_change.index)
                y_vals = df_pct_change[currency].values
                model = LinearRegression()
                model.fit(x_vals.reshape(-1, 1), y_vals)
                trend = model.predict(x_vals.reshape(-1, 1))
                plt.plot(df_pct_change.index, trend, linestyle='--', color='grey')

        plt.title(title)
        plt.ylabel('Percentage Change (%)')
        plt.xlabel('Date')

        # Format x-axis dates
        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
        plt.gca().xaxis.set_major_locator(mdates.MonthLocator())
        plt.xticks(rotation=45)

        plt.legend(title='Currency Codes')

        # Improve overall appearance
        plt.grid(True, linestyle='--', alpha=0.5)
        plt.tight_layout()

    else:
        # Handle other chart types (e.g., bar) if needed
        pass

    # Display the plot
    plt.show()

    return "Here is the visualization as per your request."

